{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["cKokiXe763vp","gc8UjK8mJFs0"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"0cc99f451bea4bf4ad223ffffaf6f2bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf086e610238417faa9f682e520a80f8","IPY_MODEL_4b1f6b41c19f49dfa52cf2293218492c","IPY_MODEL_bc976667087b497b9a42341903978275"],"layout":"IPY_MODEL_fa381d2aaf5840cab5104b528c3ecac9"}},"cf086e610238417faa9f682e520a80f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18f46dd8be9a4f94b7f1fcaf8bc2cbbc","placeholder":"​","style":"IPY_MODEL_8110a9b96817499592f1b829106a609d","value":"Downloading: 100%"}},"4b1f6b41c19f49dfa52cf2293218492c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0596d87e0042412c90a0a10e4724ebc4","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_267f42d601814f3c86e52fd817e28e2c","value":570}},"bc976667087b497b9a42341903978275":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7cbd24301aa4f03a9c04af35179c932","placeholder":"​","style":"IPY_MODEL_b35e3331f78b49dbaba50448429a6c1e","value":" 570/570 [00:00&lt;00:00, 4.24kB/s]"}},"fa381d2aaf5840cab5104b528c3ecac9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18f46dd8be9a4f94b7f1fcaf8bc2cbbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8110a9b96817499592f1b829106a609d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0596d87e0042412c90a0a10e4724ebc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"267f42d601814f3c86e52fd817e28e2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7cbd24301aa4f03a9c04af35179c932":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b35e3331f78b49dbaba50448429a6c1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f597e037fa4492eb469618572d6df8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c707e7242ef4d92b7afd9f28b07e333","IPY_MODEL_95283d91112a4f1da5b4d577b49a8b6b","IPY_MODEL_6a0c45abcb154b8fa7f8edc6ef65e50f"],"layout":"IPY_MODEL_7a8af858c2dd4cdda2f8cc17a5f25646"}},"3c707e7242ef4d92b7afd9f28b07e333":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d85d7c7fac634a808e7dba1761df94bf","placeholder":"​","style":"IPY_MODEL_40ddb3df26f94d2d91c81f734a7174ef","value":"Downloading: 100%"}},"95283d91112a4f1da5b4d577b49a8b6b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_288b41d302f04142acbec244f862cb27","max":435779157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8993a076afa4d25a0f3c0b1b28b7d46","value":435779157}},"6a0c45abcb154b8fa7f8edc6ef65e50f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b024dc2f175c4acdae94fd6fbb9cad6c","placeholder":"​","style":"IPY_MODEL_4393a8acab414d20894c8e6358944997","value":" 436M/436M [00:16&lt;00:00, 48.5MB/s]"}},"7a8af858c2dd4cdda2f8cc17a5f25646":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d85d7c7fac634a808e7dba1761df94bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40ddb3df26f94d2d91c81f734a7174ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"288b41d302f04142acbec244f862cb27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8993a076afa4d25a0f3c0b1b28b7d46":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b024dc2f175c4acdae94fd6fbb9cad6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4393a8acab414d20894c8e6358944997":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# EECS 595 Final Project\n","Zeyuan Li,   Wenbo Zhang,   Shuyan Li"],"metadata":{"id":"sxkvA2bSFxOP"}},{"cell_type":"markdown","source":["## SETUP"],"metadata":{"id":"cKokiXe763vp"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Pd9FJo5u6Wst","executionInfo":{"status":"ok","timestamp":1670048170478,"user_tz":300,"elapsed":3,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2iH3xzll7eLq","executionInfo":{"status":"ok","timestamp":1670048204879,"user_tz":300,"elapsed":34404,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"5cc58b10-85cf-4a5f-c177-c240b95bcc20"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","import sys\n","assert sys.version_info[0]==3\n","assert sys.version_info[1] >= 5\n","\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'EECS 595 NLP/final_project'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_NkyF9m7ibx","executionInfo":{"status":"ok","timestamp":1670048205741,"user_tz":300,"elapsed":864,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"802aef6e-8fae-4ec5-a34e-8ba404d212ee"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['us_train.labels', 'us_train.text', 'us_test.labels', 'us_test.text', 'X_train_3D.torch', 'model_GLOVE_BiLSTM.pt', 'X_train_2D.torch', 'X_test_2D.torch', 'model_Emb_BiLSTM.pt', 'test_clean.pkl', 'train_clean.pkl', 'X_train_BERT.torch', 'X_train_mask_BERT.torch', 'X_test_BERT.torch', 'X_test_mask_BERT.torch', 'Y_test.torch', 'Y_train.torch', 'main.ipynb']\n"]}]},{"cell_type":"code","source":["!pip install torchmetrics\n","!pip install transformers"],"metadata":{"id":"lyzeMudpIQu3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670048221188,"user_tz":300,"elapsed":15449,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"9c929ba7-f800-43a2-fcb1-aac55357a377"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[K     |████████████████████████████████| 512 kB 30.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.1.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.12.1+cu113)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.11.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 25.7 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 80.3 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 67.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}]},{"cell_type":"code","source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import os\n","import bz2\n","import pandas as pd\n","import re \n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from bs4 import BeautifulSoup\n","from textblob import TextBlob\n","import string\n","import time\n","\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from nltk.corpus import wordnet\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('omw-1.4')\n","\n","import gensim.downloader as api\n","from gensim.models import KeyedVectors\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from torchmetrics.classification import MulticlassF1Score\n","\n","from transformers import BertModel\n","from transformers import BertTokenizer\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"],"metadata":{"id":"IZQ2MrY874Ha","executionInfo":{"status":"ok","timestamp":1670048232495,"user_tz":300,"elapsed":11310,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee27e48a-ff77-4d68-eb60-c7a9d5cd395a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]}]},{"cell_type":"markdown","source":["## Data processing"],"metadata":{"id":"zNaG1hfp8wEA"}},{"cell_type":"markdown","source":["### read data"],"metadata":{"id":"P3sS9IncFcUj"}},{"cell_type":"code","source":["with open(GOOGLE_DRIVE_PATH + '/us_train.text', 'r') as f:\n","    train_txt = f.read().splitlines()\n","with open(GOOGLE_DRIVE_PATH + '/us_train.labels', 'r') as f:\n","    train_labels = f.read().splitlines()\n","with open(GOOGLE_DRIVE_PATH + '/us_test.text', 'r') as f:\n","    test_txt = f.read().splitlines()\n","with open(GOOGLE_DRIVE_PATH + '/us_test.labels', 'r') as f:\n","    test_labels = f.read().splitlines()\n"],"metadata":{"id":"B-XIJGQo8yn9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = pd.DataFrame()\n","train['text'] = train_txt\n","train['label'] = train_labels\n","train['label'] = pd.to_numeric(train['label'])\n","\n","test = pd.DataFrame()\n","test['text'] = test_txt\n","test['label'] = test_labels\n","test['label'] = pd.to_numeric(test['label'])"],"metadata":{"id":"9WRZxyGyCSUI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"XsCJXvAzD937","executionInfo":{"status":"ok","timestamp":1669349329716,"user_tz":300,"elapsed":139,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"0544843e-fb10-494d-beb1-8234e2219753"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    text  label\n","0      Cheers Steven from Mickee and Happy Birthday-T...      5\n","1      Experiencing a heat wave in East Lansing @ Mic...      6\n","2                 ️ ️ @ Southampton (village), New York       0\n","3              A few of my favorite things. @ Honey Pot       1\n","4                      in love @ Disney's Magic Kingdom       8\n","...                                                  ...    ...\n","49995  These are the mail days I love @ Lexington, Ke...      5\n","49996  With special guest appearances by arigold03 an...     10\n","49997                    Kishi. Bashi. ️ @ Sixth &amp; I      0\n","49998  Hangin' w/ @user in #hollywoodhills tonight wh...      6\n","49999  Day 6 kids and I’m in the hot tub Working on m...      6\n","\n","[50000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-3730cfce-b628-4e31-87a4-fdfb50981a69\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Cheers Steven from Mickee and Happy Birthday-T...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Experiencing a heat wave in East Lansing @ Mic...</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>️ ️ @ Southampton (village), New York</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A few of my favorite things. @ Honey Pot</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>in love @ Disney's Magic Kingdom</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>These are the mail days I love @ Lexington, Ke...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>With special guest appearances by arigold03 an...</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>Kishi. Bashi. ️ @ Sixth &amp;amp; I</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>Hangin' w/ @user in #hollywoodhills tonight wh...</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>Day 6 kids and I’m in the hot tub Working on m...</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50000 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3730cfce-b628-4e31-87a4-fdfb50981a69')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3730cfce-b628-4e31-87a4-fdfb50981a69 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3730cfce-b628-4e31-87a4-fdfb50981a69');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### clean data"],"metadata":{"id":"osyuGxLWFfKx"}},{"cell_type":"markdown","source":["#### complex method"],"metadata":{"id":"gc8UjK8mJFs0"}},{"cell_type":"code","source":["def text_processor(X):\n","    '''\n","    input: string\n","    output: list of strings\n","    example:\n","        input = 'Lens faults: I purchased this lens to attach!'\n","        output = ['lens', 'fault', 'purchase', 'lens', 'attach']\n","    '''\n","    \n","    #---------------------------------------  step1 - lowercase ----------------------------------------------------#\n","    X = X.lower()\n","    \n","    #-----------------------  step2 - url, email, time, dollar amount, emoticon with special token -----------------#   \n","    ## 1.Times   ## \n","    # 1.1 HH:MM:SS\n","    reg_time1 = \"([0-1]?[0-9]|2[0-3]):[0-5][0-9]:[0-5][0-9]\"\n","    # 1.2 HH:MM\n","    reg_time2 = \"([0-1]?[0-9]|2[0-3]):[0-5][0-9]\"\n","    X = re.sub(reg_time1, \"time\", X)\n","    X = re.sub(reg_time2, \"time\", X)\n","    \n","    ## 2.Dates  ##\n","    \n","    # 2.1 mm/dd/yyyy\n","    reg_date1 = \"(0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])[- /.](19|20)\\d\\d\"\n","    # 2.2 yyyy/mm/dd\n","    reg_date2 = \"(19|20)\\d\\d[- /.](0[1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])\"\n","    # 2.3 mm/yy/dd\n","    reg_date3 = \"(0[1-9]|[12][0-9]|3[01])[- /.](0[1-9]|1[012])[- /.](19|20)\\d\\d\"\n","    # 2.4 words like yesterday\n","    reg_date4 = \"((t|T)oday)|((y|Y)esterday)|((t|T)omorrow)|((n|N)owadays)|((n|N)owadays)|(((next)|(last)|(Next)|(Last))\\s((day)|(week)|(month)|(year)))\"\n","    X = re.sub(reg_date1, \"date\", X)\n","    X = re.sub(reg_date2, \"date\", X)\n","    X = re.sub(reg_date3, \"date\", X)\n","    X = re.sub(reg_date4, \"date\", X)\n","    \n","    ## 3.Email addresses  ##\n","    \n","    reg_email1 = \"[a-zA-Z0-9+_.-]+@[a-zA-Z0-9.-]+\"\n","    X = re.sub(reg_email1, \"email\", X)\n","    \n","    ## 4.Web addXses  ##\n","    \n","    reg_web1 = \"(http[s]?:\\/\\/(www\\.)?|ftp:\\/\\/(www\\.)?|www\\.){1}([0-9A-Za-z-\\.@:%_\\+~#=]+)+((\\.[a-zA-Z]{2,3})+)(/(.)*)?(\\?(.)*)?\"\n","    X = re.sub(reg_web1, \"website\", X)\n","\n","    \n","    ## 5.Dollar amounts  ##\n","\n","    # 5.1 $XX,XXX,XXX.XXXXX\n","    reg_dollar1 = \"\\$[0-9]+(,[0-9]{3})*\\.[0-9]*\"   \n","    # 5.2 $XX,XXX,XXX\n","    reg_dollar2 = \"\\$[0-9]+(,[0-9]{3})*\"          \n","    X = re.sub(reg_dollar1, \"dollar\", X)\n","    X = re.sub(reg_dollar2, \"dollar\", X)\n","    \n","    ## emoticon\n","    reg_emoticon_happy = \"(\\:\\))|(\\;\\))|(\\:\\-\\))|(\\:\\-\\])|(\\:D)|(\\:d)\"\n","    X = re.sub(reg_emoticon_happy, \"HAPPYEMOTICON\", X)\n","    \n","    reg_emoticon_sad = \"(\\:\\()|(\\;\\()|(\\:\\-\\()|(\\:\\-\\[)|(\\:c)|(\\:C)\"   \n","    X = re.sub(reg_emoticon_sad, \"SADEMOTICON\", X)\n","\n","   \n","    #------------------------------------  step3 - spelling correction -----------------------------------------------#\n","    textblob_ = TextBlob(X)\n","    X = textblob_.correct().string\n","    \n","    #------------------------------------  step4 - remove stopwords --------------------------------------------------#\n","    stopwords_english = stopwords.words('english')\n","    stopwords_nltk_en = set(stopwords_english)\n","    X = [word for word in X.split() if not word in stopwords_nltk_en]\n","    X = ' '.join(X)\n","    \n","    #------------------------------------  step5 - remove punctuations -----------------------------------------------#\n","    punc = string.punctuation\n","    X = X.translate(str.maketrans('', '', punc))\n","    \n","    #------------------------------------  step6 - remove digits -----------------------------------------------#\n","    X = re.sub(r'[0-9]+', '', X)\n","    \n","    #------------------------------------  step7- lemmatization -----------------------------------------------------#\n","    lemmatizer = WordNetLemmatizer()\n","    def pos_tagger(nltk_tag):\n","        if nltk_tag.startswith('J'):\n","            return wordnet.ADJ\n","        elif nltk_tag.startswith('V'):\n","            return wordnet.VERB\n","        elif nltk_tag.startswith('N'):\n","            return wordnet.NOUN\n","        elif nltk_tag.startswith('R'):\n","            return wordnet.ADV\n","        else:         \n","            return None\n","\n","    pos_tagged = nltk.pos_tag(nltk.word_tokenize(X))\n","    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n","    lemmatized_sentence = []\n","    for word, tag in wordnet_tagged:\n","        if tag is None:\n","            # if there is no available tag, append the token as is\n","            lemmatized_sentence.append(word)\n","        else:       \n","            # else use the tag to lemmatize the token\n","            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n","    X = \" \".join(lemmatized_sentence)\n","\n","    #---------------------------------------  step8 - tokenization ----------------------------------------------------#\n","    X = word_tokenize(X)\n","    \n","    return X\n","    "],"metadata":{"id":"AinoXJLrFkzr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["try 100 samples"],"metadata":{"id":"0hvzzEHwKuGf"}},{"cell_type":"code","source":["train_part = train.iloc[:1000]\n","train_part['clean_text'] = train_part['text'].apply(lambda x: text_processor(x))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmTYsIbnJnZF","executionInfo":{"status":"ok","timestamp":1669150525721,"user_tz":300,"elapsed":403304,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"f584f1c2-4bdb-48bf-e8fa-21761c610abd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}]},{"cell_type":"code","source":["train_part"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"ew_Wox7HKTEQ","executionInfo":{"status":"ok","timestamp":1669150537075,"user_tz":300,"elapsed":95,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"205abfa7-e75b-4488-d352-98d6aa7fe453"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  text  label  \\\n","0                       LoL @ West Covina, California       2   \n","1    Things got a little festive at the office #chr...     17   \n","2       Step out and explore. # ️ @ Ellis Island Cafe       0   \n","3                @user @ Cathedral Preparatory School      18   \n","4                              My baby bear @ Bubby's       1   \n","..                                                 ...    ...   \n","995                                     @ Bitzer Park      17   \n","996  I'm surrounded by beautiful friends ️ apprecia...      0   \n","997  I MADE MY BABIES! Yoshi is a black belt and be...      1   \n","998  Thank you to everyone participated in Children...      8   \n","999  In case if you are seeking the new way to wear...      6   \n","\n","                                            clean_text  \n","0                             [west, come, california]  \n","1    [thing, get, little, festive, office, christma...  \n","2               [step, explore, ️, elli, island, cafe]  \n","3               [user, cathedral, preparatory, school]  \n","4                                  [baby, bear, bobby]  \n","..                                                 ...  \n","995                                     [bitter, park]  \n","996  [im, surround, beautiful, friend, ️, appreciat...  \n","997  [make, baby, tophi, black, belt, bear, hot, do...  \n","998  [thank, everyone, participate, childrens, grie...  \n","999  [case, seek, new, way, wear, favorite, denis, ...  \n","\n","[1000 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-6dc2ebee-8bae-49da-9938-439334477f86\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>clean_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LoL @ West Covina, California</td>\n","      <td>2</td>\n","      <td>[west, come, california]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Things got a little festive at the office #chr...</td>\n","      <td>17</td>\n","      <td>[thing, get, little, festive, office, christma...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Step out and explore. # ️ @ Ellis Island Cafe</td>\n","      <td>0</td>\n","      <td>[step, explore, ️, elli, island, cafe]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@user @ Cathedral Preparatory School</td>\n","      <td>18</td>\n","      <td>[user, cathedral, preparatory, school]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>My baby bear @ Bubby's</td>\n","      <td>1</td>\n","      <td>[baby, bear, bobby]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>@ Bitzer Park</td>\n","      <td>17</td>\n","      <td>[bitter, park]</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>I'm surrounded by beautiful friends ️ apprecia...</td>\n","      <td>0</td>\n","      <td>[im, surround, beautiful, friend, ️, appreciat...</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>I MADE MY BABIES! Yoshi is a black belt and be...</td>\n","      <td>1</td>\n","      <td>[make, baby, tophi, black, belt, bear, hot, do...</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>Thank you to everyone participated in Children...</td>\n","      <td>8</td>\n","      <td>[thank, everyone, participate, childrens, grie...</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>In case if you are seeking the new way to wear...</td>\n","      <td>6</td>\n","      <td>[case, seek, new, way, wear, favorite, denis, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6dc2ebee-8bae-49da-9938-439334477f86')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6dc2ebee-8bae-49da-9938-439334477f86 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6dc2ebee-8bae-49da-9938-439334477f86');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","source":["#### simple method"],"metadata":{"id":"KAMVVo_zJdof"}},{"cell_type":"code","source":["def text_processor2(X):\n","    '''\n","    input: string\n","    output: list of strings\n","    example:\n","        input = 'Lens faults: I purchased this lens to attach!'\n","        output = ['lens', 'fault', 'purchase', 'lens', 'attach']\n","    '''\n","    #---------------------------------------  step1 - lowercase ----------------------------------------------------#\n","    X = X.lower()\n","    #print('lowercase------ ',X)\n","\n","    #------------------------------------  step4 - remove stopwords --------------------------------------------------#\n","    stopwords_english = stopwords.words('english')\n","    stopwords_nltk_en = set(stopwords_english)\n","    X = [word for word in X.split() if not word in stopwords_nltk_en]\n","    X = ' '.join(X)\n","    #print('remove stopwords------ ',X)\n","    \n","    #------------------------------------  step5 - remove punctuations -----------------------------------------------#\n","    punc = string.punctuation\n","    X = X.translate(str.maketrans('', '', punc))\n","    #print('remove punctuations------ ',X)\n","\n","    #------------------------------------  step6 - remove digits -----------------------------------------------#\n","    X = re.sub(r'[0-9]+', '', X)\n","    #print('remove digits------ ',X)\n","\n","    #---------------------------------------  step7 - remove multiple spaces ----------------------------------------------------#\n","    X = re.sub(' +', ' ', X)\n","    #print('remove multiple spaces------ ',X)\n","\n","    #---------------------------------------  step8 - tokenization ----------------------------------------------------#\n","    # X = word_tokenize(X)\n","    #print('tokenization------ ',X)\n","    return X"],"metadata":{"id":"6BD95lzNI58R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train['clean_text_string'] = train['text'].apply(lambda x: text_processor2(x))\n","test['clean_text_string'] = test['text'].apply(lambda x: text_processor2(x))\n","train['clean_text'] = train['clean_text_string'].apply(lambda x: word_tokenize(x))\n","test['clean_text'] = test['clean_text_string'].apply(lambda x: word_tokenize(x))"],"metadata":{"id":"oGwx5IqwJCpS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.to_pickle(GOOGLE_DRIVE_PATH + \"/train_clean.pkl\")\n","test.to_pickle(GOOGLE_DRIVE_PATH + \"/test_clean.pkl\")"],"metadata":{"id":"j1NS2nD6EU2k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### load clean data"],"metadata":{"id":"b68daJgsKYhy"}},{"cell_type":"code","source":["train = pd.read_pickle(GOOGLE_DRIVE_PATH + \"/train_clean.pkl\")\n","test = pd.read_pickle(GOOGLE_DRIVE_PATH + \"/test_clean.pkl\")"],"metadata":{"id":"TG_TtBeyKlie","executionInfo":{"status":"ok","timestamp":1670022699756,"user_tz":300,"elapsed":5075,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"ku7aR95VHEUR","executionInfo":{"status":"ok","timestamp":1670022948197,"user_tz":300,"elapsed":441,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"ae988084-205b-4567-8cc8-620ea5fa5ee3"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                     text  label  \\\n","0                          LoL @ West Covina, California       2   \n","1       Things got a little festive at the office #chr...     17   \n","2          Step out and explore. # ️ @ Ellis Island Cafe       0   \n","3                   @user @ Cathedral Preparatory School      18   \n","4                                 My baby bear @ Bubby's       1   \n","...                                                   ...    ...   \n","489604  Impromptu Sunday sunset picnic. #I ️SF #GGP @ ...      0   \n","489605  I think we all miss blasé more than we miss ea...      3   \n","489606  We voted! #election2016 #vote #proudtobeanamer...     11   \n","489607  Retired Jerseys, where's Chris Webber's jersey...     19   \n","489608            Millenarium wisdom! @ Red Apple Buffet      14   \n","\n","                                        clean_text_string  \\\n","0                              lol west covina california   \n","1       things got little festive office christmas red...   \n","2                        step explore ️ ellis island cafe   \n","3                       user cathedral preparatory school   \n","4                                        baby bear bubbys   \n","...                                                   ...   \n","489604  impromptu sunday sunset picnic i ️sf ggp golde...   \n","489605                     think miss blasé miss probnot…   \n","489606  voted election vote proudtobeanamerican usa br...   \n","489607  retired jerseys wheres chris webbers jersey cr...   \n","489608                millenarium wisdom red apple buffet   \n","\n","                                               clean_text  \n","0                         [lol, west, covina, california]  \n","1       [things, got, little, festive, office, christm...  \n","2                 [step, explore, ️, ellis, island, cafe]  \n","3                  [user, cathedral, preparatory, school]  \n","4                                    [baby, bear, bubbys]  \n","...                                                   ...  \n","489604  [impromptu, sunday, sunset, picnic, i, ️sf, gg...  \n","489605               [think, miss, blasé, miss, probnot…]  \n","489606  [voted, election, vote, proudtobeanamerican, u...  \n","489607  [retired, jerseys, wheres, chris, webbers, jer...  \n","489608          [millenarium, wisdom, red, apple, buffet]  \n","\n","[489609 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-95ba1b90-37e3-4e71-a3ab-0fe887fc6c52\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>clean_text_string</th>\n","      <th>clean_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LoL @ West Covina, California</td>\n","      <td>2</td>\n","      <td>lol west covina california</td>\n","      <td>[lol, west, covina, california]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Things got a little festive at the office #chr...</td>\n","      <td>17</td>\n","      <td>things got little festive office christmas red...</td>\n","      <td>[things, got, little, festive, office, christm...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Step out and explore. # ️ @ Ellis Island Cafe</td>\n","      <td>0</td>\n","      <td>step explore ️ ellis island cafe</td>\n","      <td>[step, explore, ️, ellis, island, cafe]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@user @ Cathedral Preparatory School</td>\n","      <td>18</td>\n","      <td>user cathedral preparatory school</td>\n","      <td>[user, cathedral, preparatory, school]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>My baby bear @ Bubby's</td>\n","      <td>1</td>\n","      <td>baby bear bubbys</td>\n","      <td>[baby, bear, bubbys]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>489604</th>\n","      <td>Impromptu Sunday sunset picnic. #I ️SF #GGP @ ...</td>\n","      <td>0</td>\n","      <td>impromptu sunday sunset picnic i ️sf ggp golde...</td>\n","      <td>[impromptu, sunday, sunset, picnic, i, ️sf, gg...</td>\n","    </tr>\n","    <tr>\n","      <th>489605</th>\n","      <td>I think we all miss blasé more than we miss ea...</td>\n","      <td>3</td>\n","      <td>think miss blasé miss probnot…</td>\n","      <td>[think, miss, blasé, miss, probnot…]</td>\n","    </tr>\n","    <tr>\n","      <th>489606</th>\n","      <td>We voted! #election2016 #vote #proudtobeanamer...</td>\n","      <td>11</td>\n","      <td>voted election vote proudtobeanamerican usa br...</td>\n","      <td>[voted, election, vote, proudtobeanamerican, u...</td>\n","    </tr>\n","    <tr>\n","      <th>489607</th>\n","      <td>Retired Jerseys, where's Chris Webber's jersey...</td>\n","      <td>19</td>\n","      <td>retired jerseys wheres chris webbers jersey cr...</td>\n","      <td>[retired, jerseys, wheres, chris, webbers, jer...</td>\n","    </tr>\n","    <tr>\n","      <th>489608</th>\n","      <td>Millenarium wisdom! @ Red Apple Buffet</td>\n","      <td>14</td>\n","      <td>millenarium wisdom red apple buffet</td>\n","      <td>[millenarium, wisdom, red, apple, buffet]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>489609 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95ba1b90-37e3-4e71-a3ab-0fe887fc6c52')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-95ba1b90-37e3-4e71-a3ab-0fe887fc6c52 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-95ba1b90-37e3-4e71-a3ab-0fe887fc6c52');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## model0 - baseline: Naive Bayes"],"metadata":{"id":"oMFNA-swFrjl"}},{"cell_type":"markdown","source":["### tf-idf"],"metadata":{"id":"k9N3utf1Gp8S"}},{"cell_type":"code","source":["vectorizer = TfidfVectorizer(min_df = 1000)\n","X_train_vec = vectorizer.fit_transform(train['clean_text_string'])\n","Y_train_vec = np.array(train['label'])\n","X_test_vec = vectorizer.transform(test['clean_text_string'])\n","Y_test_vec = np.array(test['label'])\n"],"metadata":{"id":"QmxD2ElvF0cN","executionInfo":{"status":"ok","timestamp":1670022969770,"user_tz":300,"elapsed":10647,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### NB"],"metadata":{"id":"LPajccmBILHw"}},{"cell_type":"code","source":["NB_model = MultinomialNB()\n","\n","NB_model.fit(X_train_vec, Y_train_vec)\n","\n","ACC_train = NB_model.score(X_train_vec, Y_train_vec)\n","ACC_test = NB_model.score(X_test_vec, Y_test_vec)\n","print(\"train accuracy: %.2f%%, test accuracy: %.2f%%\" % (ACC_train * 100.0, ACC_test * 100.0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R3MPbfT7IKk6","executionInfo":{"status":"ok","timestamp":1670023054374,"user_tz":300,"elapsed":891,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"bc43ac5d-db3e-4fd8-caa4-8edcbc3c45ce"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["train accuracy: 27.55%, test accuracy: 27.25%\n"]}]},{"cell_type":"markdown","source":["## model1 - GloVe + BiLSTM"],"metadata":{"id":"kKXW__mWF5hT"}},{"cell_type":"markdown","source":["### process data to 3D tensor"],"metadata":{"id":"9FaFlV8vK_qm"}},{"cell_type":"markdown","source":["Load word-to-vector model"],"metadata":{"id":"plV_IGU4LFp0"}},{"cell_type":"code","source":["# GloVe = api.load('glove-wiki-gigaword-100')\n","GloVe = api.load(\"glove-twitter-100\")\n","# GloVe.get_vector('11.2')\n","# GloVe_vocab = GloVe.vocab.keys()"],"metadata":{"id":"z0oyCRPZK960"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train = train_part\n","DEVICE = 'cuda:0'\n","\n","# get max length of sentences\n","max_length = 0\n","for sentence in train['clean_text']:\n","  max_length = max(max_length, len(sentence))\n","\n","\n","# train\n","N = len(train)\n","X_train = torch.zeros(N, max_length, 100, device = DEVICE)\n","Y_train = torch.tensor(train['label'], device = DEVICE)\n","for i, sentence in enumerate(train['clean_text']):\n","    this_matrix = torch.zeros(max_length, 100, device = DEVICE)\n","    for j, word in enumerate(sentence):\n","        try:\n","            this_matrix[j] = torch.tensor(GloVe.get_vector(word), device = DEVICE)\n","        except:\n","            pass\n","    X_train[i] = this_matrix\n","\n","# test\n","N = len(test)\n","X_test = torch.zeros(N, max_length, 100, device = DEVICE)\n","Y_test = torch.tensor(test['label'], device = DEVICE)\n","for i, sentence in enumerate(test['clean_text']):\n","    this_matrix = torch.zeros(max_length, 100, device = DEVICE)\n","    for j, word in enumerate(sentence):\n","        try:\n","            this_matrix[j] = torch.tensor(GloVe.get_vector(word), device = DEVICE)\n","        except:\n","            pass\n","    X_test[i] = this_matrix\n"," "],"metadata":{"id":"NIysYlBULKit"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Don't run saving here, the kernal will shut down!!!!!"],"metadata":{"id":"rZRCZEX_P3Z6"}},{"cell_type":"code","source":["torch.save(X_train, GOOGLE_DRIVE_PATH + '/X_train_3D.torch')\n","torch.save(Y_train, GOOGLE_DRIVE_PATH + '/Y_train.torch')\n","\n","torch.save(X_test, GOOGLE_DRIVE_PATH + '/X_test_3D.torch')\n","torch.save(Y_test, GOOGLE_DRIVE_PATH + '/Y_test.torch')"],"metadata":{"id":"CsvC7hjKBY2O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### load X_train and Y_train \n","- the file may not exist, because saving step failed"],"metadata":{"id":"sDtek4j3CQPY"}},{"cell_type":"code","source":["X_train = torch.load(GOOGLE_DRIVE_PATH + '/X_train_3D.torch')\n","Y_train = torch.load(GOOGLE_DRIVE_PATH + '/Y_train.torch')\n","X_test = torch.load(GOOGLE_DRIVE_PATH + '/X_test_3D.torch')\n","Y_test = torch.load(GOOGLE_DRIVE_PATH + '/Y_test.torch')"],"metadata":{"id":"RAtXy3-xPDy9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### define model"],"metadata":{"id":"EqMornZJ9SzP"}},{"cell_type":"markdown","source":["define model\n","- we keep two vectors, one for the forward (`hidden[-1, :, :]` will take the last row) and one for the backward networks (`hidden[-2, :, :]` will take the second row from the end)."],"metadata":{"id":"_pAPLtVf-LMH"}},{"cell_type":"code","source":["class BiLSTM(nn.Module):\n","    def __init__(self, sentence_length, embedding_dim, hidden_dim1, hidden_dim2, tagset_size, num_layers, dropout):\n","        super().__init__()\n","\n","        self.lstm = nn.LSTM( embedding_dim, \n","                    hidden_dim1, \n","                    num_layers = num_layers,\n","                    #dropout = dropout,\n","                    bidirectional = True,\n","                    batch_first = True)\n","        self.relu1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(p = dropout)\n","        self.fc1 = nn.Linear(2 * hidden_dim1, hidden_dim2)\n","        self.relu2 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(p = dropout)\n","        self.fc2 = nn.Linear(hidden_dim2, tagset_size)\n","\n","    def forward(self, sentence):\n","        packed_output, (hidden, cell) = self.lstm(sentence)\n","        cat = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n","        out = self.relu1(cat)\n","        out = self.dropout1(out)\n","        out = self.fc1(out)\n","        out = self.relu2(out)\n","        out = self.dropout2(out)\n","        score = self.fc2(out)\n","        return score"],"metadata":{"id":"e5LF24_tNJ3J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(X_train, Y_train, model, sentence_length, embedding_dim, hidden_dim1, hidden_dim2,\n","          tagset_size, num_layers, dropout, batch_size, epochs, lr, weight_decay, \n","          gradient_clipping, seed, device, X_test=None, Y_test=None):\n","  torch.manual_seed(seed)\n","\n","  # model definition\n","  if model == 'BiLSTM':\n","    model = BiLSTM(sentence_length, embedding_dim, hidden_dim1, hidden_dim2, tagset_size, num_layers, dropout)\n","    model = model.to(DEVICE)\n","    optomizer = torch.optim.Adam(model.parameters(),lr = lr, weight_decay = weight_decay)\n","    loss_func = nn.CrossEntropyLoss(ignore_index=0)\n","\n","\n","  # model fitting\n","  print('-------------- training model -----------------')\n","  print('Device:', DEVICE)\n","  for epoch in range(epochs):\n","      torch.manual_seed(seed)\n","      np.random.seed(seed)\n","      #  get batch data\n","      batch_data = DataLoader(list(zip(X_train, Y_train)), batch_size = batch_size, shuffle=True)\n","      for X_batch, Y_batch in batch_data:\n","          model.train()\n","          optomizer.zero_grad()\n","          logit = model.forward(X_batch)\n","          # print(logit.shape)\n","          # print(Y_batch.shape)\n","          loss = loss_func(logit, Y_batch.reshape(-1).long())\n","          loss.backward()\n","          optomizer.step()\n","\n","      model.eval()\n","      train_acc, train_f1, _ = test_model(model, X_train, Y_train)\n","      # compute test loss for each epoch, batch by batch\n","      if X_test is not None:\n","        # batch_data = DataLoader(list(zip(X_test, Y_test)), batch_size = batch_size, shuffle=True)\n","        # metric = evaluate.load(\"accuracy\")\n","        # model.eval()\n","        # loss_func_test = nn.CrossEntropyLoss(reduce='mean')\n","        # loss = 0\n","        # with torch.no_grad():\n","        #     logit = model(X_test)\n","        # loss = loss_func_test(logit, Y_test.reshape(-1).long())\n","        # predictions = torch.argmax(logit, dim=-1)\n","        # metric.add_batch(predictions=predictions, references=Y_test)\n","        # score = metric.compute()\n","        # print('Test Loss:{}, Test Accuracy:{}'.format(loss, score['accuracy']))\n","        model.eval()\n","        test_acc, test_f1, _ = test_model(model, X_test, Y_test)\n","        print('epoch:{}/{}, train loss:{}, train acc:{}, train F1:{}, test acc:{}, test F1:{}'.format(epoch, epochs, loss, train_acc,train_f1, test_acc,test_f1))\n","      else:\n","        print('epoch:{}/{}, train loss:{}, train acc:{}'.format(epoch, epochs, loss, train_acc))\n","  print('-------------- training model finished-----------------')\n","  return model \n","\n","def test_model(model, X_test, Y_test, batch_size=1000):\n","  metric = MulticlassF1Score(num_classes = 20)\n","  batch_data = DataLoader(list(zip(X_test, Y_test)), batch_size = batch_size, shuffle=True)\n","  correct_count = 0\n","  Y_pred_all = []\n","  for X_batch, Y_batch in batch_data:\n","    model.eval()\n","    Y_pred = model.forward(X_batch)\n","    Y_pred = torch.argmax(Y_pred, dim=1)\n","    correct_count += np.sum(np.array(Y_pred.cpu() == Y_batch.cpu()))\n","    Y_pred_all = Y_pred_all + Y_pred.tolist()\n","  acc = correct_count / X_test.shape[0]\n","  Y_pred_all = torch.tensor(Y_pred_all)\n","  F1_score = metric(Y_pred_all.to('cpu'), Y_test.to('cpu'))\n","  return acc, F1_score, Y_pred_all"],"metadata":{"id":"urRQrydxBx50"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### train"],"metadata":{"id":"MNJ1vfE9-Ovf"}},{"cell_type":"code","source":["params = {'model': 'BiLSTM',\n","    'sentence_length': X_train.shape[1],\n","    'embedding_dim': X_train.shape[2],\n","    'hidden_dim1': 128,\n","    'hidden_dim2': 64,\n","    'tagset_size': 20,\n","    'num_layers': 2,\n","    'dropout': 0.5,\n","    'batch_size': 128,\n","    'epochs': 30,\n","    'lr': 0.001,\n","    'weight_decay': 0,\n","    'gradient_clipping': 1000,\n","    'seed': 0,\n","    'device': DEVICE,\n","    'X_test': X_test,\n","    'Y_test': Y_test\n","}\n","model = train_model(X_train, Y_train, **params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EpfIwlicDv4K","executionInfo":{"status":"ok","timestamp":1669323837231,"user_tz":300,"elapsed":2057234,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"c6ce368e-5cf5-4ff7-bdd7-323393bcfa7b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-------------- training model -----------------\n","Device: cuda:0\n","epoch:0/30, train loss:2.647008180618286, train acc:0.25116368367411546, train F1:0.030450139194726944, test acc:0.24888, test F1:0.03024796023964882\n","epoch:1/30, train loss:2.1864891052246094, train acc:0.26470101652543154, train F1:0.03269466385245323, test acc:0.26386, test F1:0.031733568757772446\n","epoch:2/30, train loss:1.9530080556869507, train acc:0.27405950462511924, train F1:0.033490486443042755, test acc:0.27212, test F1:0.032065294682979584\n","epoch:3/30, train loss:1.7460919618606567, train acc:0.28149400848432116, train F1:0.03389430046081543, test acc:0.27752, test F1:0.0321553610265255\n","epoch:4/30, train loss:1.5543346405029297, train acc:0.2873844230804581, train F1:0.03433427959680557, test acc:0.2803, test F1:0.03236769139766693\n","epoch:5/30, train loss:1.328529715538025, train acc:0.2920064786390773, train F1:0.034449879080057144, test acc:0.28262, test F1:0.0331796258687973\n","epoch:6/30, train loss:1.2153358459472656, train acc:0.29647330829294394, train F1:0.03496063873171806, test acc:0.28446, test F1:0.032991379499435425\n","epoch:7/30, train loss:1.160324215888977, train acc:0.2998923630897308, train F1:0.03541766107082367, test acc:0.28534, test F1:0.03317877650260925\n","epoch:8/30, train loss:1.0236437320709229, train acc:0.3025883919617491, train F1:0.03562496230006218, test acc:0.28654, test F1:0.033463288098573685\n","epoch:9/30, train loss:0.9367550015449524, train acc:0.3062852194301984, train F1:0.035709161311388016, test acc:0.2869, test F1:0.03374527394771576\n","epoch:10/30, train loss:0.9248035550117493, train acc:0.3078640302772212, train F1:0.03593125566840172, test acc:0.28826, test F1:0.033558256924152374\n","epoch:11/30, train loss:0.914829432964325, train acc:0.3097349109187127, train F1:0.03612635284662247, test acc:0.29034, test F1:0.03397833928465843\n","epoch:12/30, train loss:0.901374876499176, train acc:0.31180186638726004, train F1:0.03641741722822189, test acc:0.28978, test F1:0.033883001655340195\n","epoch:13/30, train loss:0.8386159539222717, train acc:0.3135808369535691, train F1:0.03631335496902466, test acc:0.29098, test F1:0.03391459211707115\n","epoch:14/30, train loss:0.8235825896263123, train acc:0.3153169161514596, train F1:0.03624245524406433, test acc:0.29194, test F1:0.03349342197179794\n","epoch:15/30, train loss:0.7534105181694031, train acc:0.3167711377854574, train F1:0.03613084927201271, test acc:0.2911, test F1:0.03392560034990311\n","epoch:16/30, train loss:0.674733579158783, train acc:0.3162319320110537, train F1:0.036213796585798264, test acc:0.2921, test F1:0.03448577970266342\n","epoch:17/30, train loss:0.59867262840271, train acc:0.31788018602599216, train F1:0.036394454538822174, test acc:0.29336, test F1:0.03497336804866791\n","epoch:18/30, train loss:0.6520468592643738, train acc:0.31910156880286106, train F1:0.036547597497701645, test acc:0.29184, test F1:0.035064950585365295\n","epoch:19/30, train loss:0.6280778646469116, train acc:0.320521068852901, train F1:0.036797698587179184, test acc:0.29366, test F1:0.03548545390367508\n","epoch:20/30, train loss:0.5434530377388, train acc:0.3216382868778964, train F1:0.03702676668763161, test acc:0.29354, test F1:0.03564200550317764\n","epoch:21/30, train loss:0.5246201157569885, train acc:0.3224470955395019, train F1:0.03706887364387512, test acc:0.29442, test F1:0.03597266972064972\n","epoch:22/30, train loss:0.5644438862800598, train acc:0.3236398840707585, train F1:0.03706466406583786, test acc:0.29332, test F1:0.0359688401222229\n","epoch:23/30, train loss:0.4753470718860626, train acc:0.3239503358802636, train F1:0.037276074290275574, test acc:0.29288, test F1:0.03615078330039978\n","epoch:24/30, train loss:0.6309935450553894, train acc:0.32373792148428643, train F1:0.037227705121040344, test acc:0.2929, test F1:0.035779260098934174\n","epoch:25/30, train loss:0.5833458304405212, train acc:0.32485309706316673, train F1:0.03724076971411705, test acc:0.29522, test F1:0.036369387060403824\n","epoch:26/30, train loss:0.4521506130695343, train acc:0.32609081940895696, train F1:0.03688438981771469, test acc:0.29456, test F1:0.03638128563761711\n","epoch:27/30, train loss:0.4557071924209595, train acc:0.3251186150581382, train F1:0.03742392361164093, test acc:0.29418, test F1:0.036652952432632446\n","epoch:28/30, train loss:0.4445634186267853, train acc:0.32594172084254985, train F1:0.03746400773525238, test acc:0.295, test F1:0.03724395111203194\n","epoch:29/30, train loss:0.5227251648902893, train acc:0.3266790438901246, train F1:0.037576641887426376, test acc:0.29414, test F1:0.036552511155605316\n","-------------- training model finished-----------------\n"]}]},{"cell_type":"markdown","source":["save model"],"metadata":{"id":"bVYvOnLgdwIT"}},{"cell_type":"code","source":["torch.save(model, GOOGLE_DRIVE_PATH + '/model_GLOVE_BiLSTM.pt')"],"metadata":{"id":"yZbuxw_udvuQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["load model"],"metadata":{"id":"oEi4_3XBd5Or"}},{"cell_type":"code","source":["model = torch.load(GOOGLE_DRIVE_PATH + '/model_GLOVE_BiLSTM.pt')"],"metadata":{"id":"ztURo-oYd42U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["accuracy and F1"],"metadata":{"id":"yqU7Jy3VeDCO"}},{"cell_type":"code","source":["acc1, f1_1, y_pred1 = test(model, X_train, Y_train)\n","acc2, f1_2, y_pred2 = test(model, X_test, Y_test)\n","print('train accuracy:',acc1, 'test accuracy:', acc2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THLaVTrteBMe","executionInfo":{"status":"ok","timestamp":1669324144335,"user_tz":300,"elapsed":22190,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"5998b58d-3d3b-49bf-b985-e73f3fa8222d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train accuracy: 0.3266790438901246 test accuracy: 0.29414\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"7TB__ibheA4N"}},{"cell_type":"markdown","source":["## model2 - embedding layer + BiLSTM"],"metadata":{"id":"83Q58cE3GOBT"}},{"cell_type":"markdown","source":["#### create vocab_to_idx. \n","- If occurance of word <=3, then make it to be token 'UNKA'"],"metadata":{"id":"0CUovydSIIhA"}},{"cell_type":"code","source":["count = {}\n","\n","for words in train['clean_text']:\n","  for word in words:\n","    count[word] = 1 + count.get(word, 0)\n","\n","for i,sentence in enumerate(train['clean_text']):\n","    for j, word in enumerate(sentence):\n","        if count[word] < 3:\n","            train['clean_text'][i][j] = 'UNKA'\n","\n","\n","vocab_to_idx = {'UNKA': 1}\n","i = 2\n","for words in train['clean_text']:\n","  for word in words:\n","    if word not in vocab_to_idx:\n","      vocab_to_idx[word] = i\n","      i += 1\n","      if i % 10000 == 0:\n","        print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oALQnGAFGNns","executionInfo":{"status":"ok","timestamp":1669324406423,"user_tz":300,"elapsed":4987,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"b1e31c41-1db2-40fa-fe28-d9889eb5f127"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10000\n","20000\n","30000\n","40000\n","50000\n"]}]},{"cell_type":"markdown","source":["### process data to 2D tensor: N * L\n","- L is the max length of all sentences"],"metadata":{"id":"vMA0334bPhRQ"}},{"cell_type":"code","source":["DEVICE = 'cuda:0'\n","\n","# get max length of sentences\n","max_length = 0\n","for sentence in train['clean_text']:\n","  max_length = max(max_length, len(sentence))\n","\n","\n","# train\n","N = len(train)\n","X_train = torch.zeros(N, max_length, device = DEVICE)\n","Y_train = torch.tensor(train['label'], device = DEVICE)\n","for i, sentence in enumerate(train['clean_text']):\n","    this_array = torch.zeros(max_length, device = DEVICE)\n","    for j, word in enumerate(sentence):\n","      this_array[j] = torch.tensor(vocab_to_idx[word], device = DEVICE)\n","    X_train[i] = this_array\n","\n","# test \n","N = len(test)\n","X_test = torch.zeros(N, max_length, device = DEVICE)\n","Y_test = torch.tensor(test['label'], device = DEVICE)\n","for i, sentence in enumerate(test['clean_text']):\n","    this_array = torch.zeros(max_length, device = DEVICE)\n","    for j, word in enumerate(sentence):\n","      if word in vocab_to_idx:\n","        this_array[j] = torch.tensor(vocab_to_idx[word], device = DEVICE)\n","      else:\n","        this_array[j] = torch.tensor(vocab_to_idx['UNKA'], device = DEVICE)\n","    X_test[i] = this_array\n","\n"],"metadata":{"id":"xjZi_seoO72v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = X_train.to(torch.int32)\n","torch.save(X_train, GOOGLE_DRIVE_PATH + '/X_train_2D.torch')\n","torch.save(Y_train, GOOGLE_DRIVE_PATH + '/Y_train.torch')\n","\n","X_test = X_test.to(torch.int32)\n","torch.save(X_test, GOOGLE_DRIVE_PATH + '/X_test_2D.torch')\n","torch.save(Y_test, GOOGLE_DRIVE_PATH + '/Y_test.torch')"],"metadata":{"id":"3MnR6ZMQRLxy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### load X_train and Y_train"],"metadata":{"id":"oFC25gqG_qHL"}},{"cell_type":"code","source":["X_train = torch.load(GOOGLE_DRIVE_PATH + '/X_train_2D.torch')\n","Y_train = torch.load(GOOGLE_DRIVE_PATH + '/Y_train.torch')\n","X_test = torch.load(GOOGLE_DRIVE_PATH + '/X_test_2D.torch')\n","Y_test = torch.load(GOOGLE_DRIVE_PATH + '/Y_test.torch')"],"metadata":{"id":"ecLtljJz_pu1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DEVICE = 'cuda:0'\n","X_train = X_train.to(DEVICE)\n","Y_train = Y_train.to(DEVICE)\n","X_test = X_test.to(DEVICE)\n","Y_test = Y_test.to(DEVICE)"],"metadata":{"id":"7x_EuHmO_9BX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["make fake test set: sample 40000 of train + 10000 of test"],"metadata":{"id":"h58pbmrCqi0c"}},{"cell_type":"code","source":["# idx = np.arange(X_train.shape[0])\n","# val_idx = np.random.choice(idx, 40000)\n","# X_temp1 = X_train[val_idx]\n","# Y_temp1= Y_train[val_idx]\n","\n","# idx = np.arange(X_test.shape[0])\n","# val_idx = np.random.choice(idx, 10000)\n","# X_temp2 = X_test[val_idx]\n","# Y_temp2= Y_test[val_idx]\n","\n","# X_val = torch.cat((X_temp1, X_temp2), 0)\n","# Y_val = torch.cat((Y_temp1, Y_temp2), 0)"],"metadata":{"id":"RIiRjQ3uWs_V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### define model"],"metadata":{"id":"rRPB-CtRQ_QN"}},{"cell_type":"code","source":["class BiLSTM(nn.Module):\n","    def __init__(self, sentence_length, vocab_size, embedding_dim, hidden_dim1, hidden_dim2, tagset_size, num_layers, dropout):\n","        super().__init__()\n","        #self.sentence_length = torch.tensor(sentence_length)\n","\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = 0)\n","        self.lstm = nn.LSTM( embedding_dim, \n","                    hidden_dim1, \n","                    num_layers = num_layers,\n","                    #dropout = dropout,\n","                    bidirectional = True,\n","                    batch_first = True)\n","        self.relu1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(p = dropout)\n","        self.fc1 = nn.Linear(2 * hidden_dim1, hidden_dim2)\n","        self.relu2 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(p = dropout)\n","        self.fc2 = nn.Linear(hidden_dim2, tagset_size)\n","\n","    def forward(self, sentence):\n","        \n","        embedded = self.embedding(sentence)\n","        # print(embedded.shape)\n","        # packed_embedded = pack_padded_sequence(embedded, self.sentence_length, batch_first=True) \n","        packed_output, (hidden, cell) = self.lstm(embedded)\n","        cat = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n","        out = self.relu1(cat)\n","        #print('lstm_out', lstm_out.shape)\n","        # B, L, H = out.shape\n","        # out = out.reshape(B, L*H)\n","        #out = self.dropout1(out)\n","        out = self.fc1(out)\n","        #out = self.relu2(out)\n","        out = self.dropout2(out)\n","        score = self.fc2(out)\n","        return score"],"metadata":{"id":"y8d-vxLHRHFJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BiLSTM(nn.Module):\n","    def __init__(self, sentence_length, vocab_size, embedding_dim, hidden_dim1, hidden_dim2, tagset_size, num_layers, dropout):\n","        super().__init__()\n","        #self.sentence_length = torch.tensor(sentence_length)\n","\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = 0)\n","        self.lstm = nn.LSTM( embedding_dim, \n","                    hidden_dim1, \n","                    num_layers = num_layers,\n","                    #dropout = dropout,\n","                    bidirectional = True,\n","                    batch_first = True)\n","        self.relu1 = nn.ReLU()\n","        self.dropout1 = nn.Dropout(p = dropout)\n","        self.fc1 = nn.Linear(2 * hidden_dim1, hidden_dim2)\n","        self.relu2 = nn.ReLU()\n","        self.dropout2 = nn.Dropout(p = dropout)\n","        self.fc2 = nn.Linear(hidden_dim2, tagset_size)\n","\n","    def forward(self, sentence):\n","        \n","        embedded = self.embedding(sentence)\n","        # print(embedded.shape)\n","        # packed_embedded = pack_padded_sequence(embedded, self.sentence_length, batch_first=True) \n","        packed_output, (hidden, cell) = self.lstm(embedded)\n","        cat = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n","        out = self.relu1(cat)\n","        out = self.dropout1(out)\n","        out = self.fc1(out)\n","        out = self.relu2(out)\n","        out = self.dropout2(out)\n","        score = self.fc2(out)\n","        return score"],"metadata":{"id":"rq06FViGlRSp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(X_train, Y_train, model, sentence_length, vocab_size, embedding_dim, hidden_dim1, hidden_dim2,\n","          tagset_size, num_layers, dropout, batch_size, epochs, lr, weight_decay, \n","          gradient_clipping, seed, device, X_test=None, Y_test=None):\n","  torch.manual_seed(seed)\n","\n","  # model definition\n","  if model == 'BiLSTM':\n","    model = BiLSTM(sentence_length, vocab_size, embedding_dim, hidden_dim1, hidden_dim2, tagset_size, num_layers, dropout)\n","    model = model.to(DEVICE)\n","    optomizer = torch.optim.Adam(model.parameters(),lr = lr, weight_decay = weight_decay)\n","    loss_func = nn.CrossEntropyLoss(ignore_index=0)\n","  elif model == 'textCNN':\n","    pass\n","  elif model == 'BERT':\n","    pass\n","\n","  # model fitting\n","  print('-------------- training model -----------------')\n","  print('Device:', DEVICE)\n","  for epoch in range(epochs):\n","      torch.manual_seed(seed)\n","      np.random.seed(seed)\n","      #  get batch data\n","      batch_data = DataLoader(list(zip(X_train, Y_train)), batch_size = batch_size, shuffle=True)\n","      for X_batch, Y_batch in batch_data:\n","          model.train()\n","          optomizer.zero_grad()\n","          logit = model.forward(X_batch)\n","          # print(logit.shape)\n","          # print(Y_batch.shape)\n","          loss = loss_func(logit, Y_batch.reshape(-1).long())\n","          loss.backward()\n","          optomizer.step()\n","\n","      model.eval()\n","      train_acc, train_f1, _ = test_model(model, X_train, Y_train)\n","      # compute test loss for each epoch, batch by batch\n","      if X_test is not None:\n","        # batch_data = DataLoader(list(zip(X_test, Y_test)), batch_size = batch_size, shuffle=True)\n","        # metric = evaluate.load(\"accuracy\")\n","        # model.eval()\n","        # loss_func_test = nn.CrossEntropyLoss(reduce='mean')\n","        # loss = 0\n","        # with torch.no_grad():\n","        #     logit = model(X_test)\n","        # loss = loss_func_test(logit, Y_test.reshape(-1).long())\n","        # predictions = torch.argmax(logit, dim=-1)\n","        # metric.add_batch(predictions=predictions, references=Y_test)\n","        # score = metric.compute()\n","        # print('Test Loss:{}, Test Accuracy:{}'.format(loss, score['accuracy']))\n","        model.eval()\n","        test_acc, test_f1, _ = test_model(model, X_test, Y_test)\n","        print('epoch:{}/{}, train loss:{}, train acc:{}, train F1:{}, test acc:{}, test F1:{}'.format(epoch, epochs, loss, train_acc,train_f1, test_acc,test_f1))\n","      else:\n","        print('epoch:{}/{}, train loss:{}, train acc:{}'.format(epoch, epochs, loss, train_acc))\n","  print('-------------- training model finished-----------------')\n","  return model \n","\n","def test_model(model, X_test, Y_test, batch_size=1000):\n","  metric = MulticlassF1Score(num_classes = 20)\n","  batch_data = DataLoader(list(zip(X_test, Y_test)), batch_size = batch_size, shuffle=True)\n","  correct_count = 0\n","  Y_pred_all = []\n","  for X_batch, Y_batch in batch_data:\n","    model.eval()\n","    Y_pred = model.forward(X_batch)\n","    Y_pred = torch.argmax(Y_pred, dim=1)\n","    correct_count += np.sum(np.array(Y_pred.cpu() == Y_batch.cpu()))\n","    Y_pred_all = Y_pred_all + Y_pred.tolist()\n","  acc = correct_count / X_test.shape[0]\n","  Y_pred_all = torch.tensor(Y_pred_all)\n","  F1_score = metric(Y_pred_all.to('cpu'), Y_test.to('cpu'))\n","  return acc, F1_score, Y_pred_all"],"metadata":{"id":"mHpSsgSoToTw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### train"],"metadata":{"id":"TR8PmBk6HvlV"}},{"cell_type":"code","source":["params = {'model': 'BiLSTM',\n","    'sentence_length': X_train.shape[1],\n","    #'vocab_size': len(vocab_to_idx)+1,\n","    'vocab_size': 58490,\n","    'embedding_dim': 100,\n","    'hidden_dim1': 128,\n","    'hidden_dim2': 64,\n","    'tagset_size': 20,\n","    'num_layers': 2,\n","    'dropout': 0.5,\n","    'batch_size': 128,\n","    'epochs': 30,\n","    'lr': 0.001,\n","    'weight_decay': 0,\n","    'gradient_clipping': 1000,\n","    'seed': 0,\n","    'device': DEVICE,\n","    'X_test': X_test,\n","    'Y_test': Y_test\n","}\n","model = train_model(X_train, Y_train, **params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G54_dD-VT5eV","executionInfo":{"status":"ok","timestamp":1669326910129,"user_tz":300,"elapsed":2289517,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"b888a810-3a34-406c-8783-8fbb90117a6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-------------- training model -----------------\n","Device: cuda:0\n","epoch:0/30, train loss:2.824125051498413, train acc:0.25353496361382244, train F1:0.028904173523187637, test acc:0.24914, test F1:0.02808164805173874\n","epoch:1/30, train loss:2.2442729473114014, train acc:0.2793004213566336, train F1:0.030505405738949776, test acc:0.27248, test F1:0.030429981648921967\n","epoch:2/30, train loss:1.7164872884750366, train acc:0.3003049372049942, train F1:0.032392941415309906, test acc:0.28566, test F1:0.032470569014549255\n","epoch:3/30, train loss:1.4365568161010742, train acc:0.31884422059235024, train F1:0.0334390327334404, test acc:0.29718, test F1:0.0329466238617897\n","epoch:4/30, train loss:1.2427504062652588, train acc:0.3366318838093254, train F1:0.034760065376758575, test acc:0.30648, test F1:0.03396362066268921\n","epoch:5/30, train loss:1.056728482246399, train acc:0.352979622515109, train F1:0.035452235490083694, test acc:0.31532, test F1:0.034223876893520355\n","epoch:6/30, train loss:0.9745862483978271, train acc:0.36773629569717875, train F1:0.03627890348434448, test acc:0.3237, test F1:0.03491455316543579\n","epoch:7/30, train loss:0.7877002358436584, train acc:0.3804137587340102, train F1:0.03698527067899704, test acc:0.32776, test F1:0.03639881685376167\n","epoch:8/30, train loss:0.7002081871032715, train acc:0.39315453760041175, train F1:0.0376860573887825, test acc:0.33594, test F1:0.0371357724070549\n","epoch:9/30, train loss:0.5089227557182312, train acc:0.40447785886288856, train F1:0.03839262202382088, test acc:0.34062, test F1:0.03692660108208656\n","epoch:10/30, train loss:0.33110782504081726, train acc:0.4124515684964941, train F1:0.038405392318964005, test acc:0.34568, test F1:0.037584032863378525\n","epoch:11/30, train loss:0.35870108008384705, train acc:0.42104209685687966, train F1:0.03898702934384346, test acc:0.34926, test F1:0.03784213215112686\n","epoch:12/30, train loss:0.16972105205059052, train acc:0.4285133647461546, train F1:0.039434924721717834, test acc:0.35116, test F1:0.039062418043613434\n","epoch:13/30, train loss:0.12930819392204285, train acc:0.4337399843548628, train F1:0.03928520902991295, test acc:0.35522, test F1:0.03803456574678421\n","epoch:14/30, train loss:0.15628723800182343, train acc:0.4396855449961091, train F1:0.03942948207259178, test acc:0.3592, test F1:0.039559636265039444\n","epoch:15/30, train loss:0.12950727343559265, train acc:0.44570463369750146, train F1:0.039576608687639236, test acc:0.36082, test F1:0.03944304957985878\n","epoch:16/30, train loss:0.17071743309497833, train acc:0.4489643776973054, train F1:0.03981916606426239, test acc:0.36274, test F1:0.039154693484306335\n","epoch:17/30, train loss:0.09277994185686111, train acc:0.4545239160227855, train F1:0.03989149257540703, test acc:0.36608, test F1:0.03974054753780365\n","epoch:18/30, train loss:0.08209367841482162, train acc:0.45829018665915044, train F1:0.03995130583643913, test acc:0.36656, test F1:0.03950108587741852\n","epoch:19/30, train loss:0.05716586112976074, train acc:0.4620911788794732, train F1:0.04027281701564789, test acc:0.3678, test F1:0.039452724158763885\n","epoch:20/30, train loss:0.05609552934765816, train acc:0.46549185166122353, train F1:0.04009149596095085, test acc:0.37278, test F1:0.038845013827085495\n","epoch:21/30, train loss:0.04187232255935669, train acc:0.4681837956410115, train F1:0.040475815534591675, test acc:0.37216, test F1:0.039741676300764084\n","epoch:22/30, train loss:0.034684959799051285, train acc:0.47276091738509707, train F1:0.040564894676208496, test acc:0.37492, test F1:0.0394292026758194\n","epoch:23/30, train loss:0.023586267605423927, train acc:0.4760145340465555, train F1:0.04041483998298645, test acc:0.37662, test F1:0.04012186825275421\n","epoch:24/30, train loss:0.03171674534678459, train acc:0.47857984636720324, train F1:0.040420688688755035, test acc:0.37932, test F1:0.039819490164518356\n","epoch:25/30, train loss:0.01634226180613041, train acc:0.48035881693351223, train F1:0.040445975959300995, test acc:0.3804, test F1:0.03961711376905441\n","epoch:26/30, train loss:0.010423735715448856, train acc:0.4819764342567232, train F1:0.04038388654589653, test acc:0.37978, test F1:0.03955279290676117\n","epoch:27/30, train loss:0.022725192829966545, train acc:0.4842864408129752, train F1:0.04074176773428917, test acc:0.38108, test F1:0.04060550034046173\n","epoch:28/30, train loss:0.012113291770219803, train acc:0.48933945250189437, train F1:0.04101366922259331, test acc:0.38426, test F1:0.04019555076956749\n","epoch:29/30, train loss:0.01129020843654871, train acc:0.49007677554946905, train F1:0.04096280038356781, test acc:0.38522, test F1:0.039453476667404175\n","-------------- training model finished-----------------\n"]}]},{"cell_type":"markdown","source":["save model"],"metadata":{"id":"uhn5LNaceEP2"}},{"cell_type":"code","source":["torch.save(model, GOOGLE_DRIVE_PATH + '/model_Emb_BiLSTM.pt')"],"metadata":{"id":"T-KGctNOeDz0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["load model"],"metadata":{"id":"kItuaZ5sehl2"}},{"cell_type":"code","source":["model = torch.load(GOOGLE_DRIVE_PATH + '/model_Emb_BiLSTM.pt')"],"metadata":{"id":"SFviQkljeoUN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["accuracy"],"metadata":{"id":"1TE6jNKQAOX3"}},{"cell_type":"code","source":["acc1, f1_1, y_pred1 = test(model, X_train, Y_train)\n","acc2, f1_2, y_pred2 = test(model, X_val, Y_val)\n","print('train accuracy:',acc1, 'test accuracy:', acc2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHrkbOQKAN51","executionInfo":{"status":"ok","timestamp":1669273979675,"user_tz":300,"elapsed":24083,"user":{"displayName":"Zeyuan Li","userId":"18059713036684941069"}},"outputId":"a6a90c19-04dc-4b6a-f0dc-2b3ed40b942b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train accuracy: 0.49007677554946905 test accuracy: 0.43536\n"]}]},{"cell_type":"code","source":["(X_train == 58488).nonzero(as_tuple=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LMCiJP4HHmpR","executionInfo":{"status":"ok","timestamp":1669234551831,"user_tz":300,"elapsed":279,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"586975c1-68f4-427e-e4fb-c3531c992a24"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([475894, 479845, 485409]), tensor([2, 8, 2]))"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["## model3 - BERT"],"metadata":{"id":"yN21O9A1Fr4q"}},{"cell_type":"markdown","source":["### BERT tokenizer\n","- use pre-trained BERT tokenizer to turn cleaned string into tensor of ids"],"metadata":{"id":"wfA29VnT8lfI"}},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","# train_bert_input = tokenizer(list(train['clean_text_string']), padding='max_length', truncation=True, return_tensors=\"pt\")\n","# test_bert_input = tokenizer(list(test['clean_text_string']), padding='max_length', truncation=True, return_tensors=\"pt\")\n","DEVICE = 'cpu'\n","\n","# get max length of sentences\n","max_length = 0\n","for sentence in train['clean_text']:\n","  max_length = max(max_length, len(sentence))\n","\n","\n","# train\n","N = len(train)\n","# BERT will add 2 tokens [SEP] and [END] to sentence, so max_length+2\n","X_train = torch.zeros(N, max_length+2, device = DEVICE)\n","X_train_mask = torch.zeros(N, max_length+2, device = DEVICE)\n","Y_train = torch.tensor(train['label'], device = DEVICE)\n","for i, sentence in enumerate(train['clean_text_string']):\n","    train_bert_input = tokenizer(sentence, padding='max_length', max_length = max_length+2, truncation=True, return_tensors=\"pt\")\n","    X_train[i] = train_bert_input['input_ids'].to(DEVICE)\n","    X_train_mask[i] = train_bert_input['attention_mask'].to(DEVICE)\n","    if i % 10000 == 0:\n","      print(i)\n","\n","# test \n","N = len(test)\n","X_test = torch.zeros(N, max_length+2, device = DEVICE)\n","X_test_mask = torch.zeros(N, max_length+2, device = DEVICE)\n","Y_test = torch.tensor(test['label'], device = DEVICE)\n","for i, sentence in enumerate(test['clean_text_string']):\n","    test_bert_input = tokenizer(sentence, padding='max_length', max_length = max_length+2, truncation=True, return_tensors=\"pt\")\n","    X_test[i] = test_bert_input['input_ids'].to(DEVICE)\n","    X_test_mask[i] = test_bert_input['attention_mask'].to(DEVICE)\n","    if i % 10000 == 0:\n","      print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGZL13PW5uhV","executionInfo":{"status":"ok","timestamp":1669350201721,"user_tz":300,"elapsed":255087,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"2d883b23-a131-4118-cc89-43625ab012b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","10000\n","20000\n","30000\n","40000\n","50000\n","60000\n","70000\n","80000\n","90000\n","100000\n","110000\n","120000\n","130000\n","140000\n","150000\n","160000\n","170000\n","180000\n","190000\n","200000\n","210000\n","220000\n","230000\n","240000\n","250000\n","260000\n","270000\n","280000\n","290000\n","300000\n","310000\n","320000\n","330000\n","340000\n","350000\n","360000\n","370000\n","380000\n","390000\n","400000\n","410000\n","420000\n","430000\n","440000\n","450000\n","460000\n","470000\n","480000\n","0\n","10000\n","20000\n","30000\n","40000\n"]}]},{"cell_type":"code","source":["torch.save(X_train, GOOGLE_DRIVE_PATH + '/X_train_BERT.torch')\n","torch.save(X_train_mask, GOOGLE_DRIVE_PATH + '/X_train_mask_BERT.torch')\n","torch.save(Y_train, GOOGLE_DRIVE_PATH + '/Y_train.torch')\n","\n","torch.save(X_test, GOOGLE_DRIVE_PATH + '/X_test_BERT.torch')\n","torch.save(X_test_mask, GOOGLE_DRIVE_PATH + '/X_test_mask_BERT.torch')\n","torch.save(Y_test, GOOGLE_DRIVE_PATH + '/Y_test.torch')"],"metadata":{"id":"3yXXFqYNBqQ8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### load X_train"],"metadata":{"id":"JK_vYl7-BxGP"}},{"cell_type":"code","source":["X_train = torch.load(GOOGLE_DRIVE_PATH + '/X_train_BERT.torch')\n","X_train_mask = torch.load(GOOGLE_DRIVE_PATH + '/X_train_mask_BERT.torch')\n","Y_train = torch.load(GOOGLE_DRIVE_PATH + '/Y_train.torch')\n","X_test = torch.load(GOOGLE_DRIVE_PATH + '/X_test_BERT.torch')\n","X_test_mask = torch.load(GOOGLE_DRIVE_PATH + '/X_test_mask_BERT.torch')\n","Y_test = torch.load(GOOGLE_DRIVE_PATH + '/Y_test.torch')\n","\n","DEVICE = 'cpu'\n","X_train = X_train.to(torch.int32)\n","X_train = X_train.to(DEVICE)\n","X_train_mask = X_train_mask.to(DEVICE)\n","Y_train = Y_train.to(DEVICE)\n","X_test = X_test.to(torch.int32)\n","X_test = X_test.to(DEVICE)\n","X_test_mask = X_test_mask.to(DEVICE)\n","Y_test = Y_test.to(DEVICE)"],"metadata":{"id":"56LKUlKwCQ8y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NjFfPB8YDZXi","executionInfo":{"status":"ok","timestamp":1669352342195,"user_tz":300,"elapsed":306,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"2ecfd98e-dd1c-44c8-9254-75259f7de197"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[  101, 25338,  1233,  ...,     0,     0,     0],\n","        [  101,  1614,  1400,  ...,     0,     0,     0],\n","        [  101,  2585,  8664,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  4751,  1728,  ...,     0,     0,     0],\n","        [  101,  2623, 14953,  ...,     0,     0,     0],\n","        [  101,  6159,  7076,  ...,     0,     0,     0]], device='cuda:0',\n","       dtype=torch.int32)"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["### define model"],"metadata":{"id":"HT0o83U4D_p-"}},{"cell_type":"code","source":["class BERT(nn.Module):\n","\n","    def __init__(self, hidden_dim, target_size, dropout=0.5):\n","\n","        super(BERT, self).__init__()\n","\n","        self.bert = BertModel.from_pretrained('bert-base-cased')\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear = nn.Linear(hidden_dim, target_size)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, input_id, mask):\n","\n","        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask, return_dict=False)\n","        out = self.dropout(pooled_output)\n","        out = self.linear(out)\n","        #out = self.relu(out)\n","\n","        return out"],"metadata":{"id":"2nwviJVkFvrE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(X_train, X_train_mask, Y_train, hidden_dim, target_size, dropout, batch_size, epochs, lr, weight_decay, \n","          gradient_clipping, seed, device, X_test=None, Y_test=None):\n","  \n","  torch.manual_seed(seed)\n","  model = BERT(hidden_dim, target_size, dropout)\n","  model = model.to(DEVICE)\n","  optomizer = torch.optim.Adam(model.parameters(),lr = lr, weight_decay = weight_decay)\n","  loss_func = nn.CrossEntropyLoss()\n","  loss_func = loss_func.to(DEVICE)\n","  # model fitting\n","  print('-------------- training model -----------------')\n","  print('Device:', DEVICE)\n","  for epoch in range(epochs):\n","      torch.manual_seed(seed)\n","      np.random.seed(seed)\n","      #  get batch data\n","      batch_data = DataLoader(list(zip(X_train, X_train_mask, Y_train)), batch_size = batch_size, shuffle=True)\n","      for X_batch, X_mask_batch, Y_batch in batch_data:\n","          model.train()\n","          optomizer.zero_grad()\n","          logit = model.forward(X_batch, X_mask_batch)\n","          loss = loss_func(logit, Y_batch.reshape(-1).long())\n","          print(loss)\n","          loss.backward()\n","          optomizer.step()\n","\n","      model.eval()\n","      train_acc, train_f1, _ = test_model(model, X_train, X_train_mask, Y_train)\n","      # compute test loss for each epoch, batch by batch\n","      if X_test is not None:\n","        model.eval()\n","        test_acc, test_f1, _ = test_model(model, X_test, X_test_mask, Y_test)\n","        print('epoch:{}/{}, train loss:{}, train acc:{}, train F1:{}, test acc:{}, test F1:{}'.format(epoch, epochs, loss, train_acc,train_f1, test_acc,test_f1))\n","      else:\n","        print('epoch:{}/{}, train loss:{}, train acc:{}'.format(epoch, epochs, loss, train_acc))\n","  print('-------------- training model finished-----------------')\n","  return model \n","\n","def test_model(model, X_test, X_test_mask, Y_test, batch_size=1000):\n","  metric = MulticlassF1Score(num_classes = 20)\n","  batch_data = DataLoader(list(zip(X_test, X_test_mask, Y_test)), batch_size = batch_size, shuffle=True)\n","  correct_count = 0\n","  Y_pred_all = []\n","  for X_batch, X_mask_batch, Y_batch in batch_data:\n","    model.eval()\n","    Y_pred = model.forward(X_batch, X_mask_batch)\n","    Y_pred = torch.argmax(Y_pred, dim=1)\n","    correct_count += np.sum(np.array(Y_pred.cpu() == Y_batch.cpu()))\n","    Y_pred_all = Y_pred_all + Y_pred.tolist()\n","  acc = correct_count / X_test.shape[0]\n","  Y_pred_all = torch.tensor(Y_pred_all)\n","  F1_score = metric(Y_pred_all.to('cpu'), Y_test.to('cpu'))\n","  return acc, F1_score, Y_pred_all"],"metadata":{"id":"Jc6GESTL4fr5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### train"],"metadata":{"id":"e3yS33CtE7s3"}},{"cell_type":"code","source":["params = {\n","    'hidden_dim': 768,\n","    'target_size': 20,\n","    'dropout': 0.5,\n","    'batch_size': 128,\n","    'epochs': 30,\n","    'lr': 0.0001,\n","    'weight_decay': 0,\n","    'gradient_clipping': 1000,\n","    'seed': 0,\n","    'device': DEVICE,\n","    'X_test': X_test,\n","    'Y_test': Y_test\n","}\n","model = train_model(X_train[:10], X_train_mask[:10], Y_train[:10], **params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205,"referenced_widgets":["0cc99f451bea4bf4ad223ffffaf6f2bc","cf086e610238417faa9f682e520a80f8","4b1f6b41c19f49dfa52cf2293218492c","bc976667087b497b9a42341903978275","fa381d2aaf5840cab5104b528c3ecac9","18f46dd8be9a4f94b7f1fcaf8bc2cbbc","8110a9b96817499592f1b829106a609d","0596d87e0042412c90a0a10e4724ebc4","267f42d601814f3c86e52fd817e28e2c","f7cbd24301aa4f03a9c04af35179c932","b35e3331f78b49dbaba50448429a6c1e","8f597e037fa4492eb469618572d6df8e","3c707e7242ef4d92b7afd9f28b07e333","95283d91112a4f1da5b4d577b49a8b6b","6a0c45abcb154b8fa7f8edc6ef65e50f","7a8af858c2dd4cdda2f8cc17a5f25646","d85d7c7fac634a808e7dba1761df94bf","40ddb3df26f94d2d91c81f734a7174ef","288b41d302f04142acbec244f862cb27","a8993a076afa4d25a0f3c0b1b28b7d46","b024dc2f175c4acdae94fd6fbb9cad6c","4393a8acab414d20894c8e6358944997"]},"id":"dSO7MXYjE88J","outputId":"498f907e-4533-49f4-eaf8-c040a06e3ed5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cc99f451bea4bf4ad223ffffaf6f2bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f597e037fa4492eb469618572d6df8e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["-------------- training model -----------------\n","Device: cpu\n","tensor(3.2027, grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"markdown","source":["***Attention: BERT needs to be trained on Great Lakes***"],"metadata":{"id":"mZbF7EK0sv6S"}},{"cell_type":"markdown","source":["## model 4 - text CNN"],"metadata":{"id":"YLd-4FbHL1hH"}},{"cell_type":"markdown","source":["### load X_train\n","- the same as the input of model 2 - embedding layer + BiLSTM"],"metadata":{"id":"K1O4CqQqadE-"}},{"cell_type":"code","source":["X_train = torch.load(GOOGLE_DRIVE_PATH + '/X_train_2D.torch')\n","Y_train = torch.load(GOOGLE_DRIVE_PATH + '/Y_train.torch')\n","X_test = torch.load(GOOGLE_DRIVE_PATH + '/X_test_2D.torch')\n","Y_test = torch.load(GOOGLE_DRIVE_PATH + '/Y_test.torch')\n","\n","DEVICE = 'cuda:0'\n","X_train = X_train.to(torch.int32)\n","X_train = X_train.to(DEVICE)\n","X_train_mask = X_train_mask.to(DEVICE)\n","Y_train = Y_train.to(DEVICE)\n","X_test = X_test.to(torch.int32)\n","X_test = X_test.to(DEVICE)\n","X_test_mask = X_test_mask.to(DEVICE)\n","Y_test = Y_test.to(DEVICE)"],"metadata":{"id":"6asN96JTL3gP","executionInfo":{"status":"ok","timestamp":1670048331896,"user_tz":300,"elapsed":5188,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### define model"],"metadata":{"id":"CIB_0Ul2aiwa"}},{"cell_type":"code","source":["class textCNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, n_filters, target_size, dropout, hidden_size, pool_size, filter_sizes):\n","        super().__init__()        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.convs = nn.ModuleList([nn.Conv2d(in_channels = 1,\n","                             out_channels = n_filters,\n","                             kernel_size = (fs, embedding_dim)) \n","                        for fs in filter_sizes])\n","        self.max_pool1 = nn.MaxPool1d(pool_size)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc1 = nn.Linear(33*n_filters, hidden_size, bias=True)  \n","        self.fc2 = nn.Linear(hidden_size, target_size, bias=True)  \n","\n","    def forward(self, text):\n","        embedded = self.embedding(text)\n","        embedded = embedded.unsqueeze(1)      \n","        convolution = [conv(embedded) for conv in self.convs]   \n","        max1 = self.max_pool1(convolution[0].squeeze()) \n","        max2 = self.max_pool1(convolution[1].squeeze())\n","        #print('max1', max1.shape)\n","        #print('max2', max2.shape)\n","        cat = torch.cat((max1, max2), dim=2)\n","        #print('cat', cat.shape)      \n","        x = cat.view(cat.shape[0], -1) \n","        x = self.fc1(self.relu(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)  \n","        return x"],"metadata":{"id":"zCIWmp3Vakem","executionInfo":{"status":"ok","timestamp":1670048404922,"user_tz":300,"elapsed":320,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def train_model(X_train, Y_train, model, vocab_size, embedding_dim, n_filters,\n","          tagset_size, dropout, hidden_size, pool_size, filter_sizes\n","          ,batch_size, epochs, lr, weight_decay, \n","          gradient_clipping, seed, device, X_test=None, Y_test=None):\n","  torch.manual_seed(seed)\n","\n","  # model definition\n","  model = textCNN(vocab_size, embedding_dim, n_filters, tagset_size, dropout, hidden_size, pool_size, filter_sizes)\n","  model = model.to(DEVICE)\n","  optomizer = torch.optim.Adam(model.parameters(),lr = lr, weight_decay = weight_decay)\n","  loss_func = nn.CrossEntropyLoss()\n","\n","  # model fitting\n","  print('-------------- training model -----------------')\n","  print('Device:', DEVICE)\n","  for epoch in range(epochs):\n","      torch.manual_seed(seed)\n","      np.random.seed(seed)\n","      #  get batch data\n","      batch_data = DataLoader(list(zip(X_train, Y_train)), batch_size = batch_size, shuffle=True)\n","      for X_batch, Y_batch in batch_data:\n","          model.train()\n","          optomizer.zero_grad()\n","          logit = model.forward(X_batch)\n","          # print(logit.shape)\n","          # print(Y_batch.shape)\n","          loss = loss_func(logit, Y_batch.reshape(-1).long())\n","          loss.backward()\n","          optomizer.step()\n","\n","      model.eval()\n","      train_acc, train_f1, _ = test_model(model, X_train, Y_train)\n","      # compute test loss for each epoch, batch by batch\n","      if X_test is not None:\n","        # batch_data = DataLoader(list(zip(X_test, Y_test)), batch_size = batch_size, shuffle=True)\n","        # metric = evaluate.load(\"accuracy\")\n","        # model.eval()\n","        # loss_func_test = nn.CrossEntropyLoss(reduce='mean')\n","        # loss = 0\n","        # with torch.no_grad():\n","        #     logit = model(X_test)\n","        # loss = loss_func_test(logit, Y_test.reshape(-1).long())\n","        # predictions = torch.argmax(logit, dim=-1)\n","        # metric.add_batch(predictions=predictions, references=Y_test)\n","        # score = metric.compute()\n","        # print('Test Loss:{}, Test Accuracy:{}'.format(loss, score['accuracy']))\n","        model.eval()\n","        test_acc, test_f1, _ = test_model(model, X_test, Y_test)\n","        print('epoch:{}/{}, train loss:{}, train acc:{}, train F1:{}, test acc:{}, test F1:{}'.format(epoch, epochs, loss, train_acc,train_f1, test_acc,test_f1))\n","      else:\n","        print('epoch:{}/{}, train loss:{}, train acc:{}'.format(epoch, epochs, loss, train_acc))\n","  print('-------------- training model finished-----------------')\n","  return model \n","\n","def test_model(model, X_test, Y_test, batch_size=1000):\n","  metric = MulticlassF1Score(num_classes = 20)\n","  batch_data = DataLoader(list(zip(X_test, Y_test)), batch_size = batch_size, shuffle=True)\n","  correct_count = 0\n","  Y_pred_all = []\n","  for X_batch, Y_batch in batch_data:\n","    model.eval()\n","    Y_pred = model.forward(X_batch)\n","    Y_pred = torch.argmax(Y_pred, dim=1)\n","    correct_count += np.sum(np.array(Y_pred.cpu() == Y_batch.cpu()))\n","    Y_pred_all = Y_pred_all + Y_pred.tolist()\n","  acc = correct_count / X_test.shape[0]\n","  Y_pred_all = torch.tensor(Y_pred_all)\n","  F1_score = metric(Y_pred_all.to('cpu'), Y_test.to('cpu'))\n","  return acc, F1_score, Y_pred_all"],"metadata":{"id":"z_rc2Y6hcuC_","executionInfo":{"status":"ok","timestamp":1670048385630,"user_tz":300,"elapsed":566,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["### train"],"metadata":{"id":"lI9U9mJ1dv5B"}},{"cell_type":"code","source":["params = {'model': 'textCNN',\n","    'vocab_size': 58490,\n","    'embedding_dim': 100,\n","    'n_filters': 128,\n","    'tagset_size': 20,\n","    'dropout': 0.5,\n","    'hidden_size': 128,\n","    'pool_size': 2,\n","    'filter_sizes': [3, 8],\n","    'batch_size': 128,\n","    'epochs': 5,\n","    'lr': 0.001,\n","    'weight_decay': 0,\n","    'gradient_clipping': 1000,\n","    'seed': 0,\n","    'device': DEVICE,\n","    'X_test': X_test,\n","    'Y_test': Y_test\n","}\n","model = train_model(X_train, Y_train, **params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5kRmYDuidw7H","executionInfo":{"status":"ok","timestamp":1670050323058,"user_tz":300,"elapsed":1281023,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}},"outputId":"4a3cec6a-6997-49c6-a330-6d6333f4a79f"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["-------------- training model -----------------\n","Device: cuda:0\n","epoch:0/5, train loss:1.92983877658844, train acc:0.4077539424316138, train F1:0.04053816199302673, test acc:0.3955, test F1:0.03986789286136627\n","epoch:1/5, train loss:1.3237147331237793, train acc:0.4399939543594991, train F1:0.04280932620167732, test acc:0.42082, test F1:0.042638279497623444\n","epoch:2/5, train loss:0.7139589190483093, train acc:0.4632533307190023, train F1:0.04432101920247078, test acc:0.43648, test F1:0.04369222745299339\n","epoch:3/5, train loss:0.3186221122741699, train acc:0.48211736303866964, train F1:0.04540267586708069, test acc:0.4479, test F1:0.04550362378358841\n","epoch:4/5, train loss:0.10799559950828552, train acc:0.4980361880602685, train F1:0.046328503638505936, test acc:0.45524, test F1:0.046244703233242035\n","-------------- training model finished-----------------\n"]}]},{"cell_type":"code","source":["torch.save(model, GOOGLE_DRIVE_PATH + '/model_textCNN.pt')"],"metadata":{"id":"FIAc4HDGzOiT","executionInfo":{"status":"ok","timestamp":1670051082340,"user_tz":300,"elapsed":295,"user":{"displayName":"Zeyuan Li","userId":"01753479507224786455"}}},"execution_count":28,"outputs":[]}]}